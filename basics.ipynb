{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSL_logo](dsl_logo.png)\n",
    "\n",
    "\n",
    "# Introduction to Text Analysis with Python\n",
    "\n",
    "Welcome to the Digital Scholarship Lab introduction to Text Analysis with Python class. In this class we'll learn the basics of text analysis:\n",
    "\n",
    "- parsing text\n",
    "- analyzing the text\n",
    "\n",
    "We'll use our own home made analysis tool first, then we'll use a python library called `gensim` to use some built in analysis tools.\n",
    "\n",
    "This workshop assumes you've completed our self-paced Python prep [workshop](https://brockdsl.github.io/Intro_to_Python_Workshop/)\n",
    "\n",
    "We'll use the Zoom's chat feature to interact.\n",
    "\n",
    "Be sure to enable line numbers by looking for the 'gear' icon and checking the box in the 'Editor' panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EG. Scrabble!\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Scrabble_game_in_progress.jpg\" width =500x>\n",
    "\n",
    "Scrabble is a popular game where players try to score points by spelling words and placing them on the game board. We'll use Scrabble scoring our our first attempt at text analysis. This will demonstart the basics of how Text Analysis works.\n",
    "\n",
    "The function below gives you the Scrabble scored of any word you give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the Scrabble score of a word\n",
    "\n",
    "def scrabble_score(word):\n",
    "    \n",
    "    #Dictionary of our scrabble scores\n",
    "    score_lookup = {\n",
    "        \"a\": 1,\n",
    "        \"b\": 3,\n",
    "        \"c\": 3,\n",
    "        \"d\": 2,\n",
    "        \"e\": 1,\n",
    "        \"f\": 4,\n",
    "        \"g\": 2,\n",
    "        \"h\": 4,\n",
    "        \"i\": 1,\n",
    "        \"j\": 8,\n",
    "        \"k\": 5,\n",
    "        \"l\": 1,\n",
    "        \"m\": 3,\n",
    "        \"n\": 1,\n",
    "        \"o\": 1,\n",
    "        \"p\": 3,\n",
    "        \"q\": 10,\n",
    "        \"r\": 1,\n",
    "        \"s\": 1,\n",
    "        \"t\": 1,\n",
    "        \"u\": 1,\n",
    "        \"v\": 4,\n",
    "        \"w\": 4,\n",
    "        \"x\": 8,\n",
    "        \"y\": 4,\n",
    "        \"z\": 10,\n",
    "        \"\\n\": 0, #just in case a new line character jumps in here\n",
    "        \" \":0 #normally single words don't have spaces but we'll put this here just in case\n",
    "        \n",
    "    }\n",
    "    \n",
    "    total_score = 0\n",
    "    \n",
    "    #We look up each letter in the scoring dictionary and add it to a running total\n",
    "    #to make our dictionary shorter we are just using lowercase letters so we need to\n",
    "    #change all of our input to lowercase with .lower()\n",
    "    for letter in word:\n",
    "        total_score = total_score + score_lookup[letter.lower()]\n",
    "    \n",
    "    return total_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis is a process comprised of three basic steps:\n",
    "1. Identifying the text (or corpus) that you'd like to an analyze\n",
    "1. Apply the analysis to your prepared text\n",
    "1. Analyze the results\n",
    "\n",
    "In our very basic example of scrabble we just are interested in finding the points we would get for spelling a specific word. \n",
    "\n",
    "In a more complext example with a larger corpus you can do any of the following types of analysis:\n",
    "- determine the sentiment (positive / negative nature) of the text\n",
    "- quantify how complex a piece of writing is based on the vocabulary it uses\n",
    "- determine what topics are in your corpus, and match your items to these topics (this is what we are going to do)\n",
    "\n",
    "Of course, there are many other different outcomes you can get from peforming text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try questions Q1 - Q2 and type \"All Done\" in the chat box when you are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Score your name\n",
    "\n",
    "How many Points do you get for your name? Complete the expression below to find out the scrabble score of your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for my name is: 5\n"
     ]
    }
   ],
   "source": [
    "name = \"Tim\"\n",
    "print(\"Score for my name is:\", scrabble_score(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Score the name of your pet or favorite character from a story. Does your name or the name of your pet score higher in Scrabble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for my pet's name is: 9\n",
      "My pet's name scores more points!\n"
     ]
    }
   ],
   "source": [
    "pet_name = \"Domino\"\n",
    "print(\"Score for my pet's name is:\",scrabble_score(pet_name))\n",
    "\n",
    "#Compare to see which gets more points!\n",
    "if scrabble_score(pet_name) > scrabble_score(name):\n",
    "    print(\"My pet's name scores more points!\")\n",
    "else:\n",
    "    print(\"My name scores more (or the same) amount of points as my pets name\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the basics\n",
    "\n",
    "We just completed a very basic text analysis where we analyzed two different bits of text to see which one scores higher in Scrabble. Let's expand this idea to a more complex example using the [gensim](https://radimrehurek.com/gensim/) and [TextBlob](https://textblob.readthedocs.io/en/dev/) Python Libraries. There are other more complex libraries that you can use for text analysis, we are using more simple solutions so we can spend more time looking at results compared to setting up our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing\n",
    "\n",
    "This next cell will install and load the requires libraries that will do the text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/tim/opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/tim/opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in /Users/tim/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to /Users/tim/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Install textblob using magic commands\n",
    "#Only needed once\n",
    "%pip install textblob\n",
    "#%python -m textblob.download_corpora\n",
    "#%pip install textblob.download_corpora\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "#import gensim\n",
    "#from gensim import corpora, models, similarities, downloader\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "\n",
    "#Let's make sure our previews show more information\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "\n",
    "Corpus is a fancy way of saying the text that we will be looking at. Typically a corpus is already cleaned up and ready for your analysis. For our example we are going to be looking at some entries from the 1900 [diary](https://dr.library.brocku.ca/handle/10464/7282) of Winnie Beam. The next cell will load this corpus and show us a few entires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>date</th>\n",
       "      <th>entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>New Year. First day of 1900 Charlie Merritt died at Grand Forks British Columbia yesterday of typhoid fever. To-day is election day and pap went up about 3 o'clock and did not get back until nearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1900-01-02</td>\n",
       "      <td>Went uptown in afternoon. Was up to Eckardt's but Miss Macfarlane was not there so I did not get what I wanted. Called at office and Nettie came home with me for tea. Mr Carman came over and borro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1900-01-03</td>\n",
       "      <td>Mrs Trusty was here washing School started to-day, but I was not going this week. Mamma went to the church and then to Mrs Chatfields Took her the church books. The queen Street Baptist church had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1900-01-04</td>\n",
       "      <td>Went over to Carman's to have Ella go with me to Dunn's greenhouse. We went about half past three. I brought a primrose Miss Chaplin was in there. Mamma went to Mrs Klotz at home Beatrice helped. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1900-01-05</td>\n",
       "      <td>Sweep day. I read \"At the Camerons\" in the \"Harper's Young People\" when mamma was sweeping. We had a beggar in afternoon asking for a few cents as he had a long way to go. Rats! Went over to Lee's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page       date  \\\n",
       "0     7 1900-01-01   \n",
       "1     7 1900-01-02   \n",
       "2     8 1900-01-03   \n",
       "3     8 1900-01-04   \n",
       "4     9 1900-01-05   \n",
       "\n",
       "                                                                                                                                                                                                     entry  \n",
       "0  New Year. First day of 1900 Charlie Merritt died at Grand Forks British Columbia yesterday of typhoid fever. To-day is election day and pap went up about 3 o'clock and did not get back until nearl...  \n",
       "1  Went uptown in afternoon. Was up to Eckardt's but Miss Macfarlane was not there so I did not get what I wanted. Called at office and Nettie came home with me for tea. Mr Carman came over and borro...  \n",
       "2  Mrs Trusty was here washing School started to-day, but I was not going this week. Mamma went to the church and then to Mrs Chatfields Took her the church books. The queen Street Baptist church had...  \n",
       "3  Went over to Carman's to have Ella go with me to Dunn's greenhouse. We went about half past three. I brought a primrose Miss Chaplin was in there. Mamma went to Mrs Klotz at home Beatrice helped. ...  \n",
       "4  Sweep day. I read \"At the Camerons\" in the \"Harper's Young People\" when mamma was sweeping. We had a beggar in afternoon asking for a few cents as he had a long way to go. Rats! Went over to Lee's...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winnie_corpus = pd.read_csv('https://raw.githubusercontent.com/BrockDSL/Text_Analysis_with_Python/master/winnie_corpus.txt', header = None, delimiter=\"\\t\")\n",
    "winnie_corpus.columns = [\"page\",\"date\",\"entry\"]\n",
    "winnie_corpus['date'] = pd.to_datetime(winnie_corpus['date'])\n",
    "winnie_corpus['entry'] = winnie_corpus.entry.astype(str)\n",
    "\n",
    "#preview our top entries\n",
    "winnie_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Sentiment\n",
    "\n",
    "We can analyze the _sentiment_ of text using `textBlob`. The next cell demonstrates this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "happy_sentence = \"Python is the best programming language ever!\"\n",
    "sad_sentence = \"Python is difficult to use, and very frustrating\"\n",
    "\n",
    "\n",
    "print(\"Sentiment of happy sentence \", TextBlob(happy_sentence).sentiment)\n",
    "print(\"Sentiment of sad sentence \", TextBlob(sad_sentence).sentiment)\n",
    "\n",
    "# polarity ranges from -1 to 1.\n",
    "# subjectvity ranges from 0 to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "\n",
    "Try a couple of different sentences in the code cell below. See if you can create something that scores -1 and another that scores 1 for _polarity_. See if you can minimize the _subjectivity_ of your sentence. Share your answers in the chat box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\n",
    "print(\"Score of test sentence is \", TextBlob(test_sentence).sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Sentiment to our Diary entries\n",
    "\n",
    "This next cell will score each diary entry in a new column that will be added to the dataframe. We loop through each entry, calculate the two scores that represent the sentiment. After all the scores are computed with add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply sentiment analysis from TextBlob\n",
    "\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "\n",
    "\n",
    "for day in winnie_corpus.entry:\n",
    "    #print(day,\"\\n\")\n",
    "    score = TextBlob(day)\n",
    "    polarity.append(score.sentiment.polarity)\n",
    "    subjectivity.append(score.sentiment.subjectivity)\n",
    "    \n",
    "winnie_corpus['polarity'] = polarity\n",
    "winnie_corpus['subjectvitity'] = subjectivity\n",
    "\n",
    "\n",
    "#Let's look at our new top entries\n",
    "winnie_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's graph out the sentiment as it changes day to day.\n",
    "\n",
    "plt.plot(winnie_corpus[\"date\"],winnie_corpus[\"polarity\"])\n",
    "plt.xticks(rotation='45')\n",
    "plt.title(\"Sentiment of Winnie's Diary Entries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What else can we get from the text?\n",
    "\n",
    "Let's grab a random entry and see what we can find out about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_of_corpus = TextBlob(winnie_corpus[\"entry\"][22])\n",
    "bit_of_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in bit_of_corpus.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.sentiment,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in bit_of_corpus.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at the corpus\n",
    "\n",
    "Let's look at the January Diary entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#January Entries\n",
    "#jan_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-01-01') & (winnie_corpus['date'] <= '1900-01-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what Winnie talks about the most in the month. We can do this by extracting the _noun phrases_ in her entries. We can put them in a dictionary to count how many times a phrase is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-9fb93aa5ef82>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9fb93aa5ef82>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrases = {}\n",
    "\n",
    "for entry in jan_corpus.entries:\n",
    "    tb = TextBlob(entry)\n",
    "    for np in tp.noun_phrases:\n",
    "        # check/add to dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#January Entries\n",
    "#jan_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-01-01') & (winnie_corpus['date'] <= '1900-01-31')]\n",
    "\n",
    "#February Entries\n",
    "#feb_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-02-01') & (winnie_corpus['date'] <= '1900-02-28')]\n",
    "\n",
    "#March Entries\n",
    "#mar_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-03-01') & (winnie_corpus['date'] <= '1900-03-31')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
